{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objetivo\n",
    "O objetivo deste trabalho é reproduzir o trabalho feito por [Ali Al Bataineh e Devinder Kaur](https://ieeexplore.ieee.org/abstract/document/8556738) e depois introduzir um algoritmo de Feature Selection e analisar o ganho de performance, como custo computacional para treinar o modelo e performance geral. O trabalho será usado como trabalho final na matéria de Inteligência Artificial, ministrada para os alunos da pós em Ciência da Computação pela Universidade Federal de Uberlândia (UFU), em 2021-2.\n",
    "\n",
    "Alunos: Marcos Tomé, Patrick Araújo e Pedro Reis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introdução\n",
    "A base de dados usada neste estudo chama-se [Boston House Prices](https://www.kaggle.com/vikrishnan/boston-house-prices/version/1) e contém dados oriundos do US Census Service, que levantou o preço de casas na região de Boston, MA em 1970.\n",
    "\n",
    "A base contém 14 atributos, sendo:\n",
    "\n",
    "1. CRIM: taxa de crimes per capita na cidade;\n",
    "2. ZN: proporção de terrenos residenciaiszoneados para lotes com mais de 25.000 pés quadrados;\n",
    "3. INDUS: proporção de acres de negócios não varejistas na cidade;\n",
    "3. CHAS: variável que indica áreas tangentes a rios (1 se a área é tangente a um rio, 0 caso contrário);\n",
    "4. NOX: concentração de óxidos nítricos (em partes por 10 milhões);\n",
    "5. RM: número médio de quartos por residência;\n",
    "6. AGE: proporção de unidades ocupadas que foram construídas antes de 1940;\n",
    "7. DIS: distâncias podenradas para cinco centros comerciais;\n",
    "8. RAD: índice de acessibilidade às rodovias radiais;\n",
    "9. TAX: valor total da taxa de imposto sobre a propriedade por U$10.000;\n",
    "10. PTRATIO: proporção aluno-professor na cidade;\n",
    "11. B: 1000(Bk - 0.63)² onde Bk é a proporção de negros na cidade;\n",
    "12. LSTAT: porcentagem da camada inferior da população;\n",
    "13. MEDV: valor médio das casas ocupadas pelos proprietários em U$1.000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parte 1 - Reprodução do trabalho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if not os.path.exists('tf-levenberg-marquardt'):\n",
    "    os.system('git clone  https://github.com/fabiodimarco/tf-levenberg-marquardt')\n",
    "\n",
    "sys.path.append('tf-levenberg-marquardt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries necessary for this project\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "\n",
    "import levenberg_marquardt as lm\n",
    "\n",
    "# Pretty display for notebooks\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296.0   \n",
       "1  0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242.0   \n",
       "2  0.02729   0.0   7.07     0  0.469  7.185  61.1  4.9671    2  242.0   \n",
       "3  0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222.0   \n",
       "4  0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  MEDV  \n",
       "0     15.3  396.90   4.98  24.0  \n",
       "1     17.8  396.90   9.14  21.6  \n",
       "2     17.8  392.83   4.03  34.7  \n",
       "3     18.7  394.63   2.94  33.4  \n",
       "4     18.7  396.90   5.33  36.2  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#column names for house features\n",
    "column_names = ['CRIM', 'ZN', 'INDUS', 'CHAS', 'NOX', 'RM', 'AGE', 'DIS', 'RAD', 'TAX', 'PTRATIO', 'B', 'LSTAT', 'MEDV']\n",
    "\n",
    "#assigning columns names to our data\n",
    "data = pd.read_csv(\"housing.csv\", header=None, delimiter=r\"\\s+\", names=column_names)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/patrick/anaconda3/lib/python3.8/site-packages/seaborn/distributions.py:2557: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='MEDV', ylabel='Density'>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualização da distribuição dos preços dos imóveis\n",
    "sns.distplot(data['MEDV'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>MEDV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "      <td>506.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.613524</td>\n",
       "      <td>11.363636</td>\n",
       "      <td>11.136779</td>\n",
       "      <td>0.069170</td>\n",
       "      <td>0.554695</td>\n",
       "      <td>6.284634</td>\n",
       "      <td>68.574901</td>\n",
       "      <td>3.795043</td>\n",
       "      <td>9.549407</td>\n",
       "      <td>408.237154</td>\n",
       "      <td>18.455534</td>\n",
       "      <td>356.674032</td>\n",
       "      <td>12.653063</td>\n",
       "      <td>22.532806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.601545</td>\n",
       "      <td>23.322453</td>\n",
       "      <td>6.860353</td>\n",
       "      <td>0.253994</td>\n",
       "      <td>0.115878</td>\n",
       "      <td>0.702617</td>\n",
       "      <td>28.148861</td>\n",
       "      <td>2.105710</td>\n",
       "      <td>8.707259</td>\n",
       "      <td>168.537116</td>\n",
       "      <td>2.164946</td>\n",
       "      <td>91.294864</td>\n",
       "      <td>7.141062</td>\n",
       "      <td>9.197104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.006320</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.460000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.385000</td>\n",
       "      <td>3.561000</td>\n",
       "      <td>2.900000</td>\n",
       "      <td>1.129600</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>187.000000</td>\n",
       "      <td>12.600000</td>\n",
       "      <td>0.320000</td>\n",
       "      <td>1.730000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.082045</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.190000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.449000</td>\n",
       "      <td>5.885500</td>\n",
       "      <td>45.025000</td>\n",
       "      <td>2.100175</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>279.000000</td>\n",
       "      <td>17.400000</td>\n",
       "      <td>375.377500</td>\n",
       "      <td>6.950000</td>\n",
       "      <td>17.025000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.256510</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.690000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.538000</td>\n",
       "      <td>6.208500</td>\n",
       "      <td>77.500000</td>\n",
       "      <td>3.207450</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>330.000000</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>391.440000</td>\n",
       "      <td>11.360000</td>\n",
       "      <td>21.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.677083</td>\n",
       "      <td>12.500000</td>\n",
       "      <td>18.100000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.624000</td>\n",
       "      <td>6.623500</td>\n",
       "      <td>94.075000</td>\n",
       "      <td>5.188425</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>666.000000</td>\n",
       "      <td>20.200000</td>\n",
       "      <td>396.225000</td>\n",
       "      <td>16.955000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>88.976200</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>27.740000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.871000</td>\n",
       "      <td>8.780000</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>12.126500</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>711.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>396.900000</td>\n",
       "      <td>37.970000</td>\n",
       "      <td>50.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             CRIM          ZN       INDUS        CHAS         NOX          RM  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean     3.613524   11.363636   11.136779    0.069170    0.554695    6.284634   \n",
       "std      8.601545   23.322453    6.860353    0.253994    0.115878    0.702617   \n",
       "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
       "25%      0.082045    0.000000    5.190000    0.000000    0.449000    5.885500   \n",
       "50%      0.256510    0.000000    9.690000    0.000000    0.538000    6.208500   \n",
       "75%      3.677083   12.500000   18.100000    0.000000    0.624000    6.623500   \n",
       "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.780000   \n",
       "\n",
       "              AGE         DIS         RAD         TAX     PTRATIO           B  \\\n",
       "count  506.000000  506.000000  506.000000  506.000000  506.000000  506.000000   \n",
       "mean    68.574901    3.795043    9.549407  408.237154   18.455534  356.674032   \n",
       "std     28.148861    2.105710    8.707259  168.537116    2.164946   91.294864   \n",
       "min      2.900000    1.129600    1.000000  187.000000   12.600000    0.320000   \n",
       "25%     45.025000    2.100175    4.000000  279.000000   17.400000  375.377500   \n",
       "50%     77.500000    3.207450    5.000000  330.000000   19.050000  391.440000   \n",
       "75%     94.075000    5.188425   24.000000  666.000000   20.200000  396.225000   \n",
       "max    100.000000   12.126500   24.000000  711.000000   22.000000  396.900000   \n",
       "\n",
       "            LSTAT        MEDV  \n",
       "count  506.000000  506.000000  \n",
       "mean    12.653063   22.532806  \n",
       "std      7.141062    9.197104  \n",
       "min      1.730000    5.000000  \n",
       "25%      6.950000   17.025000  \n",
       "50%     11.360000   21.200000  \n",
       "75%     16.955000   25.000000  \n",
       "max     37.970000   50.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treino:  354\n",
      "Validação:  76\n",
      "Teste:  76\n"
     ]
    }
   ],
   "source": [
    "# Divisão da base entre treino, validação e teste\n",
    "# Treino = \n",
    "# Validação = \n",
    "# Teste = 15%\n",
    "X = data.drop(\"MEDV\", axis=1)\n",
    "y = data['MEDV']\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "train_ratio = 0.7\n",
    "validation_ratio = 0.15\n",
    "test_ratio = 0.15\n",
    "\n",
    "# train is now 75% of the entire data set\n",
    "# the _junk suffix means that we drop that variable completely\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1 - train_ratio)\n",
    "\n",
    "# test is now 10% of the initial data set\n",
    "# validation is now 15% of the initial data set\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, test_size=test_ratio/(test_ratio + validation_ratio)) \n",
    "\n",
    "print(\"Treino: \", len(X_train))\n",
    "print(\"Validação: \", len(X_val))\n",
    "print(\"Teste: \", len(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criação do modelo\n",
    "model = Sequential()\n",
    "\n",
    "# Camada de entrada\n",
    "model.add(Input(shape=(X_train.shape[1],)))\n",
    "\n",
    "# Camada profunda\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "\n",
    "#Camada de saída\n",
    "model.add(Dense(1, activation='linear'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adamax(learning_rate=0.001),\n",
    "              loss='mean_squared_error')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit\n",
    "#model_wrapper = lm.ModelWrapper(tf.keras.models.clone_model(model))\n",
    "#model_wrapper.compile(optimizer = tf.keras.optimizers.SGD(),\n",
    "#                      loss = lm.MeanSquaredError())\n",
    "#\n",
    "#X_train_edited = tf.expand_dims(tf.cast(X_train, tf.float32), axis=-1)\n",
    "#y_train_edited = tf.expand_dims(tf.cast(y_train, tf.float32), axis=-1)\n",
    "#\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "#\n",
    "#train_dataset = tf.data.Dataset.from_tensor_slices((X_train_edited, y_train_edited))\n",
    "#train_dataset = train_dataset.shuffle(len(X_train_edited))\n",
    "#train_dataset = train_dataset.batch(len(X_train_edited)/20).cache()\n",
    "#train_dataset = train_dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "#\n",
    "#model_fitted = model_wrapper.fit(train_dataset,\n",
    "#                                 epochs=20,\n",
    "#                                 validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import Callback\n",
    "import warnings\n",
    "\n",
    "class EarlyStoppingByLossVal(Callback):\n",
    "    def __init__(self, monitor='val_loss', value=14.017, verbose=0):\n",
    "        super(Callback, self).__init__()\n",
    "        self.monitor = monitor\n",
    "        self.value = value\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        current = logs.get(self.monitor)\n",
    "        if current is None:\n",
    "            warnings.warn(\"Early stopping requires %s available!\" % self.monitor, RuntimeWarning)\n",
    "\n",
    "        if current < self.value:\n",
    "            if self.verbose > 0:\n",
    "                print(\"Epoch %05d: early stopping THR\" % epoch)\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.5816 - val_loss: 25.7370\n",
      "Epoch 2/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.4468 - val_loss: 25.7545\n",
      "Epoch 3/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.8974 - val_loss: 26.3038\n",
      "Epoch 4/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.4471 - val_loss: 25.9222\n",
      "Epoch 5/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 34.0759 - val_loss: 26.4750\n",
      "Epoch 6/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.5208 - val_loss: 25.9417\n",
      "Epoch 7/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.4006 - val_loss: 25.8023\n",
      "Epoch 8/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.5440 - val_loss: 26.3105\n",
      "Epoch 9/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.4569 - val_loss: 26.1756\n",
      "Epoch 10/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.3485 - val_loss: 25.8690\n",
      "Epoch 11/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.2785 - val_loss: 25.8260\n",
      "Epoch 12/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.2749 - val_loss: 25.8370\n",
      "Epoch 13/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2739 - val_loss: 25.8040\n",
      "Epoch 14/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2725 - val_loss: 25.7571\n",
      "Epoch 15/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2578 - val_loss: 25.8051\n",
      "Epoch 16/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.3360 - val_loss: 25.6965\n",
      "Epoch 17/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.2760 - val_loss: 25.6924\n",
      "Epoch 18/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.2515 - val_loss: 25.7405\n",
      "Epoch 19/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.2953 - val_loss: 25.7965\n",
      "Epoch 20/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 33.2684 - val_loss: 25.9692\n",
      "Epoch 21/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 33.5976 - val_loss: 26.2960\n",
      "Epoch 22/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.5546 - val_loss: 25.9865\n",
      "Epoch 23/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.3027 - val_loss: 25.8949\n",
      "Epoch 24/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2386 - val_loss: 25.8027\n",
      "Epoch 25/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2871 - val_loss: 25.7111\n",
      "Epoch 26/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.2674 - val_loss: 25.7498\n",
      "Epoch 27/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2353 - val_loss: 25.7563\n",
      "Epoch 28/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2474 - val_loss: 25.7326\n",
      "Epoch 29/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2574 - val_loss: 25.7746\n",
      "Epoch 30/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2401 - val_loss: 25.7644\n",
      "Epoch 31/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2539 - val_loss: 25.7573\n",
      "Epoch 32/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2332 - val_loss: 25.8437\n",
      "Epoch 33/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2380 - val_loss: 25.8200\n",
      "Epoch 34/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.3369 - val_loss: 25.8350\n",
      "Epoch 35/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2410 - val_loss: 25.7165\n",
      "Epoch 36/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2457 - val_loss: 25.6928\n",
      "Epoch 37/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2707 - val_loss: 25.7081\n",
      "Epoch 38/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2453 - val_loss: 25.7469\n",
      "Epoch 39/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3545 - val_loss: 26.0036\n",
      "Epoch 40/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.3999 - val_loss: 25.7834\n",
      "Epoch 41/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2295 - val_loss: 25.8556\n",
      "Epoch 42/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.2856 - val_loss: 26.1934\n",
      "Epoch 43/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.4391 - val_loss: 25.9701\n",
      "Epoch 44/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.3072 - val_loss: 25.7639\n",
      "Epoch 45/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.2201 - val_loss: 25.7231\n",
      "Epoch 46/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2359 - val_loss: 25.7025\n",
      "Epoch 47/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2303 - val_loss: 25.6971\n",
      "Epoch 48/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2341 - val_loss: 25.7404\n",
      "Epoch 49/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2295 - val_loss: 25.7374\n",
      "Epoch 50/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2283 - val_loss: 25.8272\n",
      "Epoch 51/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2443 - val_loss: 25.7917\n",
      "Epoch 52/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2141 - val_loss: 25.7388\n",
      "Epoch 53/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2582 - val_loss: 25.6773\n",
      "Epoch 54/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2878 - val_loss: 25.7250\n",
      "Epoch 55/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2727 - val_loss: 25.6977\n",
      "Epoch 56/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2622 - val_loss: 25.7039\n",
      "Epoch 57/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2712 - val_loss: 25.7020\n",
      "Epoch 58/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3464 - val_loss: 25.8255\n",
      "Epoch 59/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2455 - val_loss: 25.7295\n",
      "Epoch 60/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2199 - val_loss: 25.7523\n",
      "Epoch 61/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2172 - val_loss: 25.8083\n",
      "Epoch 62/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2194 - val_loss: 25.7744\n",
      "Epoch 63/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2905 - val_loss: 25.7908\n",
      "Epoch 64/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1482 - val_loss: 25.7185\n",
      "Epoch 65/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.7445 - val_loss: 25.9287\n",
      "Epoch 66/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.8828 - val_loss: 25.9132\n",
      "Epoch 67/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.7537 - val_loss: 25.7679\n",
      "Epoch 68/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.5006 - val_loss: 25.6957\n",
      "Epoch 69/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3861 - val_loss: 25.6922\n",
      "Epoch 70/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2279 - val_loss: 25.7238\n",
      "Epoch 71/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2023 - val_loss: 25.7363\n",
      "Epoch 72/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2001 - val_loss: 25.7468\n",
      "Epoch 73/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2086 - val_loss: 25.7452\n",
      "Epoch 74/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1968 - val_loss: 25.7590\n",
      "Epoch 75/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2111 - val_loss: 25.7748\n",
      "Epoch 76/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2193 - val_loss: 25.7483\n",
      "Epoch 77/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2021 - val_loss: 25.7643\n",
      "Epoch 78/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2009 - val_loss: 25.7806\n",
      "Epoch 79/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2297 - val_loss: 25.8545\n",
      "Epoch 80/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2547 - val_loss: 25.7832\n",
      "Epoch 81/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.3208 - val_loss: 25.9691\n",
      "Epoch 82/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2591 - val_loss: 25.9286\n",
      "Epoch 83/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2292 - val_loss: 25.8810\n",
      "Epoch 84/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2243 - val_loss: 25.8267\n",
      "Epoch 85/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2063 - val_loss: 25.7810\n",
      "Epoch 86/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1935 - val_loss: 25.7371\n",
      "Epoch 87/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2079 - val_loss: 25.7463\n",
      "Epoch 88/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2153 - val_loss: 25.7753\n",
      "Epoch 89/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2151 - val_loss: 25.7841\n",
      "Epoch 90/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1897 - val_loss: 25.7696\n",
      "Epoch 91/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1921 - val_loss: 25.7574\n",
      "Epoch 92/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2278 - val_loss: 25.7464\n",
      "Epoch 93/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1839 - val_loss: 25.7834\n",
      "Epoch 94/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2040 - val_loss: 25.7946\n",
      "Epoch 95/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2133 - val_loss: 25.8184\n",
      "Epoch 96/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1929 - val_loss: 25.8226\n",
      "Epoch 97/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2512 - val_loss: 25.9929\n",
      "Epoch 98/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3154 - val_loss: 25.9031\n",
      "Epoch 99/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2486 - val_loss: 25.8666\n",
      "Epoch 100/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2137 - val_loss: 25.8402\n",
      "Epoch 101/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2035 - val_loss: 25.8118\n",
      "Epoch 102/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2184 - val_loss: 25.8229\n",
      "Epoch 103/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2043 - val_loss: 25.8335\n",
      "Epoch 104/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2025 - val_loss: 25.8075\n",
      "Epoch 105/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2206 - val_loss: 25.8707\n",
      "Epoch 106/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2220 - val_loss: 25.8362\n",
      "Epoch 107/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2256 - val_loss: 25.7616\n",
      "Epoch 108/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1947 - val_loss: 25.7805\n",
      "Epoch 109/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2243 - val_loss: 26.0112\n",
      "Epoch 110/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2860 - val_loss: 26.0314\n",
      "Epoch 111/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3448 - val_loss: 26.1312\n",
      "Epoch 112/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3044 - val_loss: 25.9811\n",
      "Epoch 113/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2421 - val_loss: 25.9193\n",
      "Epoch 114/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2326 - val_loss: 26.1763\n",
      "Epoch 115/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.4313 - val_loss: 26.2498\n",
      "Epoch 116/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.3991 - val_loss: 26.0155\n",
      "Epoch 117/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.2564 - val_loss: 25.8807\n",
      "Epoch 118/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2029 - val_loss: 25.8365\n",
      "Epoch 119/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1844 - val_loss: 25.7884\n",
      "Epoch 120/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1917 - val_loss: 25.7488\n",
      "Epoch 121/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2193 - val_loss: 25.7371\n",
      "Epoch 122/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1985 - val_loss: 25.7841\n",
      "Epoch 123/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1809 - val_loss: 25.8030\n",
      "Epoch 124/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.1968 - val_loss: 25.7901\n",
      "Epoch 125/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1996 - val_loss: 25.8219\n",
      "Epoch 126/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1953 - val_loss: 25.8153\n",
      "Epoch 127/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2059 - val_loss: 25.7736\n",
      "Epoch 128/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2057 - val_loss: 25.7435\n",
      "Epoch 129/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2743 - val_loss: 25.8953\n",
      "Epoch 130/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2082 - val_loss: 25.8563\n",
      "Epoch 131/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2218 - val_loss: 25.7340\n",
      "Epoch 132/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2008 - val_loss: 25.7222\n",
      "Epoch 133/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2233 - val_loss: 25.7176\n",
      "Epoch 134/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2039 - val_loss: 25.7609\n",
      "Epoch 135/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1900 - val_loss: 25.8253\n",
      "Epoch 136/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2056 - val_loss: 25.8732\n",
      "Epoch 137/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1865 - val_loss: 25.8236\n",
      "Epoch 138/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2238 - val_loss: 25.7624\n",
      "Epoch 139/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2365 - val_loss: 25.8133\n",
      "Epoch 140/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2535 - val_loss: 25.9247\n",
      "Epoch 141/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1952 - val_loss: 25.8447\n",
      "Epoch 142/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1807 - val_loss: 25.8045\n",
      "Epoch 143/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1975 - val_loss: 25.7819\n",
      "Epoch 144/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2344 - val_loss: 25.8036\n",
      "Epoch 145/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1973 - val_loss: 25.7702\n",
      "Epoch 146/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1856 - val_loss: 25.7855\n",
      "Epoch 147/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2384 - val_loss: 25.7540\n",
      "Epoch 148/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1930 - val_loss: 25.8334\n",
      "Epoch 149/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1901 - val_loss: 25.8459\n",
      "Epoch 150/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2445 - val_loss: 25.7690\n",
      "Epoch 151/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1808 - val_loss: 25.7998\n",
      "Epoch 152/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1837 - val_loss: 25.8003\n",
      "Epoch 153/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2559 - val_loss: 25.7604\n",
      "Epoch 154/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2026 - val_loss: 25.7891\n",
      "Epoch 155/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2189 - val_loss: 25.7831\n",
      "Epoch 156/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1872 - val_loss: 25.8350\n",
      "Epoch 157/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1858 - val_loss: 25.8318\n",
      "Epoch 158/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1736 - val_loss: 25.7756\n",
      "Epoch 159/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.1966 - val_loss: 25.7399\n",
      "Epoch 160/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1898 - val_loss: 25.7511\n",
      "Epoch 161/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1807 - val_loss: 25.7454\n",
      "Epoch 162/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1991 - val_loss: 25.7711\n",
      "Epoch 163/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3304 - val_loss: 25.6713\n",
      "Epoch 164/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2216 - val_loss: 25.7086\n",
      "Epoch 165/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1751 - val_loss: 25.7519\n",
      "Epoch 166/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1675 - val_loss: 25.6970\n",
      "Epoch 167/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2435 - val_loss: 25.7472\n",
      "Epoch 168/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2054 - val_loss: 25.7391\n",
      "Epoch 169/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1719 - val_loss: 25.7867\n",
      "Epoch 170/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2021 - val_loss: 25.9282\n",
      "Epoch 171/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1877 - val_loss: 25.8094\n",
      "Epoch 172/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1694 - val_loss: 25.7644\n",
      "Epoch 173/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1783 - val_loss: 25.8004\n",
      "Epoch 174/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1888 - val_loss: 25.7985\n",
      "Epoch 175/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1903 - val_loss: 25.7532\n",
      "Epoch 176/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1931 - val_loss: 25.7670\n",
      "Epoch 177/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1793 - val_loss: 25.7774\n",
      "Epoch 178/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1684 - val_loss: 25.7927\n",
      "Epoch 179/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1747 - val_loss: 25.8659\n",
      "Epoch 180/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1933 - val_loss: 25.8801\n",
      "Epoch 181/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3223 - val_loss: 25.9470\n",
      "Epoch 182/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3317 - val_loss: 25.7144\n",
      "Epoch 183/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3071 - val_loss: 25.8995\n",
      "Epoch 184/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1473 - val_loss: 26.1759\n",
      "Epoch 185/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.5809 - val_loss: 26.1097\n",
      "Epoch 186/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1733 - val_loss: 25.7234\n",
      "Epoch 187/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1757 - val_loss: 25.6579\n",
      "Epoch 188/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2367 - val_loss: 25.6819\n",
      "Epoch 189/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2037 - val_loss: 25.7120\n",
      "Epoch 190/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0830 - val_loss: 25.8760\n",
      "Epoch 191/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2397 - val_loss: 25.9915\n",
      "Epoch 192/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.3189 - val_loss: 25.9626\n",
      "Epoch 193/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2874 - val_loss: 25.6928\n",
      "Epoch 194/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2044 - val_loss: 25.7130\n",
      "Epoch 195/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2757 - val_loss: 25.6440\n",
      "Epoch 196/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2033 - val_loss: 25.7427\n",
      "Epoch 197/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1959 - val_loss: 25.8027\n",
      "Epoch 198/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1715 - val_loss: 25.7389\n",
      "Epoch 199/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1685 - val_loss: 25.7103\n",
      "Epoch 200/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1569 - val_loss: 25.6966\n",
      "Epoch 201/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2381 - val_loss: 26.0127\n",
      "Epoch 202/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3389 - val_loss: 25.7548\n",
      "Epoch 203/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2665 - val_loss: 25.6434\n",
      "Epoch 204/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.3570 - val_loss: 25.7475\n",
      "Epoch 205/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1463 - val_loss: 25.7009\n",
      "Epoch 206/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1827 - val_loss: 25.6631\n",
      "Epoch 207/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3911 - val_loss: 25.6474\n",
      "Epoch 208/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.4239 - val_loss: 25.5955\n",
      "Epoch 209/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3097 - val_loss: 25.6549\n",
      "Epoch 210/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3009 - val_loss: 25.6060\n",
      "Epoch 211/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3446 - val_loss: 25.7682\n",
      "Epoch 212/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1721 - val_loss: 25.7042\n",
      "Epoch 213/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1674 - val_loss: 25.6687\n",
      "Epoch 214/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1704 - val_loss: 25.6534\n",
      "Epoch 215/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2548 - val_loss: 25.7417\n",
      "Epoch 216/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1568 - val_loss: 25.6520\n",
      "Epoch 217/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1627 - val_loss: 25.6401\n",
      "Epoch 218/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1624 - val_loss: 25.6603\n",
      "Epoch 219/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1966 - val_loss: 25.6688\n",
      "Epoch 220/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2067 - val_loss: 25.7098\n",
      "Epoch 221/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1477 - val_loss: 25.6401\n",
      "Epoch 222/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1414 - val_loss: 25.7828\n",
      "Epoch 223/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1692 - val_loss: 25.8153\n",
      "Epoch 224/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1500 - val_loss: 25.7562\n",
      "Epoch 225/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1788 - val_loss: 25.7219\n",
      "Epoch 226/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2540 - val_loss: 25.7265\n",
      "Epoch 227/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1298 - val_loss: 25.9102\n",
      "Epoch 228/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2127 - val_loss: 25.8116\n",
      "Epoch 229/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2015 - val_loss: 25.7952\n",
      "Epoch 230/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1307 - val_loss: 25.7076\n",
      "Epoch 231/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1517 - val_loss: 25.7065\n",
      "Epoch 232/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2347 - val_loss: 25.8537\n",
      "Epoch 233/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1162 - val_loss: 25.7094\n",
      "Epoch 234/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2539 - val_loss: 25.6132\n",
      "Epoch 235/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2107 - val_loss: 25.6760\n",
      "Epoch 236/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1834 - val_loss: 25.7520\n",
      "Epoch 237/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1757 - val_loss: 25.7162\n",
      "Epoch 238/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2200 - val_loss: 25.6758\n",
      "Epoch 239/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2561 - val_loss: 25.9061\n",
      "Epoch 240/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.4107 - val_loss: 26.3242\n",
      "Epoch 241/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.4624 - val_loss: 25.7567\n",
      "Epoch 242/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1661 - val_loss: 25.7360\n",
      "Epoch 243/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2159 - val_loss: 25.6494\n",
      "Epoch 244/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.1495 - val_loss: 25.6977\n",
      "Epoch 245/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.2172 - val_loss: 25.8416\n",
      "Epoch 246/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1578 - val_loss: 25.7135\n",
      "Epoch 247/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1418 - val_loss: 25.6533\n",
      "Epoch 248/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.1653 - val_loss: 25.6593\n",
      "Epoch 249/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.1864 - val_loss: 25.6827\n",
      "Epoch 250/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.1725 - val_loss: 25.8852\n",
      "Epoch 251/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.2403 - val_loss: 25.7306\n",
      "Epoch 252/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0439 - val_loss: 26.0998\n",
      "Epoch 253/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.4217 - val_loss: 26.2662\n",
      "Epoch 254/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.3517 - val_loss: 25.8230\n",
      "Epoch 255/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1203 - val_loss: 25.6972\n",
      "Epoch 256/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1672 - val_loss: 25.7211\n",
      "Epoch 257/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1351 - val_loss: 25.7714\n",
      "Epoch 258/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1806 - val_loss: 25.8512\n",
      "Epoch 259/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1549 - val_loss: 25.7696\n",
      "Epoch 260/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1821 - val_loss: 25.8347\n",
      "Epoch 261/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1164 - val_loss: 25.7577\n",
      "Epoch 262/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1569 - val_loss: 25.7209\n",
      "Epoch 263/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.3111 - val_loss: 26.2140\n",
      "Epoch 264/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.2933 - val_loss: 25.9256\n",
      "Epoch 265/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.2991 - val_loss: 25.6693\n",
      "Epoch 266/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 33.3724 - val_loss: 25.7285\n",
      "Epoch 267/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1447 - val_loss: 25.7514\n",
      "Epoch 268/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1500 - val_loss: 25.8233\n",
      "Epoch 269/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1283 - val_loss: 25.8119\n",
      "Epoch 270/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1446 - val_loss: 25.8057\n",
      "Epoch 271/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1648 - val_loss: 25.7278\n",
      "Epoch 272/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1197 - val_loss: 25.7417\n",
      "Epoch 273/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1149 - val_loss: 25.7521\n",
      "Epoch 274/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1433 - val_loss: 25.7236\n",
      "Epoch 275/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1786 - val_loss: 25.7636\n",
      "Epoch 276/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1169 - val_loss: 25.7937\n",
      "Epoch 277/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1617 - val_loss: 25.7899\n",
      "Epoch 278/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1472 - val_loss: 25.7576\n",
      "Epoch 279/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0549 - val_loss: 26.0311\n",
      "Epoch 280/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2439 - val_loss: 25.9808\n",
      "Epoch 281/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1482 - val_loss: 25.8221\n",
      "Epoch 282/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1708 - val_loss: 25.7309\n",
      "Epoch 283/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2180 - val_loss: 25.8214\n",
      "Epoch 284/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1549 - val_loss: 25.7631\n",
      "Epoch 285/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1666 - val_loss: 25.8728\n",
      "Epoch 286/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1528 - val_loss: 25.8680\n",
      "Epoch 287/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1324 - val_loss: 25.8242\n",
      "Epoch 288/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1344 - val_loss: 25.7802\n",
      "Epoch 289/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1548 - val_loss: 25.7750\n",
      "Epoch 290/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1191 - val_loss: 25.9446\n",
      "Epoch 291/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2420 - val_loss: 25.9426\n",
      "Epoch 292/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1285 - val_loss: 25.8123\n",
      "Epoch 293/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1354 - val_loss: 25.7843\n",
      "Epoch 294/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1732 - val_loss: 25.7752\n",
      "Epoch 295/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1005 - val_loss: 25.8519\n",
      "Epoch 296/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1237 - val_loss: 25.9272\n",
      "Epoch 297/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1116 - val_loss: 25.7860\n",
      "Epoch 298/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1508 - val_loss: 25.8034\n",
      "Epoch 299/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1116 - val_loss: 25.8197\n",
      "Epoch 300/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0912 - val_loss: 26.0359\n",
      "Epoch 301/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.3406 - val_loss: 25.8098\n",
      "Epoch 302/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1307 - val_loss: 25.8811\n",
      "Epoch 303/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2018 - val_loss: 25.7891\n",
      "Epoch 304/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1400 - val_loss: 25.9098\n",
      "Epoch 305/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1414 - val_loss: 25.9237\n",
      "Epoch 306/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1557 - val_loss: 25.7723\n",
      "Epoch 307/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1092 - val_loss: 25.8367\n",
      "Epoch 308/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1380 - val_loss: 25.7987\n",
      "Epoch 309/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1560 - val_loss: 25.8437\n",
      "Epoch 310/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1227 - val_loss: 26.3468\n",
      "Epoch 311/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.3232 - val_loss: 26.1058\n",
      "Epoch 312/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1123 - val_loss: 25.8312\n",
      "Epoch 313/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1017 - val_loss: 25.7944\n",
      "Epoch 314/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1498 - val_loss: 25.7504\n",
      "Epoch 315/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1697 - val_loss: 25.8519\n",
      "Epoch 316/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1021 - val_loss: 25.8209\n",
      "Epoch 317/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1175 - val_loss: 25.8079\n",
      "Epoch 318/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1205 - val_loss: 25.8291\n",
      "Epoch 319/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1013 - val_loss: 25.8036\n",
      "Epoch 320/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1458 - val_loss: 25.8984\n",
      "Epoch 321/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.1067 - val_loss: 25.6479\n",
      "Epoch 322/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.2090 - val_loss: 25.6610\n",
      "Epoch 323/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0821 - val_loss: 25.8381\n",
      "Epoch 324/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1464 - val_loss: 25.9390\n",
      "Epoch 325/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1151 - val_loss: 25.9115\n",
      "Epoch 326/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1059 - val_loss: 25.8618\n",
      "Epoch 327/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0945 - val_loss: 25.8781\n",
      "Epoch 328/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0685 - val_loss: 25.9825\n",
      "Epoch 329/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.1459 - val_loss: 25.9787\n",
      "Epoch 330/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.1299 - val_loss: 25.9273\n",
      "Epoch 331/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.1051 - val_loss: 25.8762\n",
      "Epoch 332/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1086 - val_loss: 25.8203\n",
      "Epoch 333/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0842 - val_loss: 25.8091\n",
      "Epoch 334/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0840 - val_loss: 25.7836\n",
      "Epoch 335/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0735 - val_loss: 25.7704\n",
      "Epoch 336/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0803 - val_loss: 25.7598\n",
      "Epoch 337/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0775 - val_loss: 25.7587\n",
      "Epoch 338/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0820 - val_loss: 25.7536\n",
      "Epoch 339/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0957 - val_loss: 25.7750\n",
      "Epoch 340/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0748 - val_loss: 25.7643\n",
      "Epoch 341/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0840 - val_loss: 25.7513\n",
      "Epoch 342/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1173 - val_loss: 25.8012\n",
      "Epoch 343/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0729 - val_loss: 25.7818\n",
      "Epoch 344/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0748 - val_loss: 25.7719\n",
      "Epoch 345/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0956 - val_loss: 25.8098\n",
      "Epoch 346/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0937 - val_loss: 25.8680\n",
      "Epoch 347/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0814 - val_loss: 25.8391\n",
      "Epoch 348/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0733 - val_loss: 25.7831\n",
      "Epoch 349/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0731 - val_loss: 25.7718\n",
      "Epoch 350/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0890 - val_loss: 25.7361\n",
      "Epoch 351/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0785 - val_loss: 25.7494\n",
      "Epoch 352/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0744 - val_loss: 25.7835\n",
      "Epoch 353/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9906 - val_loss: 26.0002\n",
      "Epoch 354/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1535 - val_loss: 26.0696\n",
      "Epoch 355/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1600 - val_loss: 25.9254\n",
      "Epoch 356/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1479 - val_loss: 25.8019\n",
      "Epoch 357/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0752 - val_loss: 25.8203\n",
      "Epoch 358/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0692 - val_loss: 25.8147\n",
      "Epoch 359/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0684 - val_loss: 25.8003\n",
      "Epoch 360/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0691 - val_loss: 25.8097\n",
      "Epoch 361/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0854 - val_loss: 25.8355\n",
      "Epoch 362/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0670 - val_loss: 25.8284\n",
      "Epoch 363/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1488 - val_loss: 25.7458\n",
      "Epoch 364/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0781 - val_loss: 25.7479\n",
      "Epoch 365/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1291 - val_loss: 25.8225\n",
      "Epoch 366/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0727 - val_loss: 25.8146\n",
      "Epoch 367/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0605 - val_loss: 25.8113\n",
      "Epoch 368/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0718 - val_loss: 25.8355\n",
      "Epoch 369/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0735 - val_loss: 25.8122\n",
      "Epoch 370/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0614 - val_loss: 25.8325\n",
      "Epoch 371/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0729 - val_loss: 25.8054\n",
      "Epoch 372/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0790 - val_loss: 25.7840\n",
      "Epoch 373/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0784 - val_loss: 25.7933\n",
      "Epoch 374/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0662 - val_loss: 25.7892\n",
      "Epoch 375/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0675 - val_loss: 25.8060\n",
      "Epoch 376/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0835 - val_loss: 25.7827\n",
      "Epoch 377/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0813 - val_loss: 25.8370\n",
      "Epoch 378/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0595 - val_loss: 25.8418\n",
      "Epoch 379/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0731 - val_loss: 25.8706\n",
      "Epoch 380/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2275 - val_loss: 26.1886\n",
      "Epoch 381/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2435 - val_loss: 26.1043\n",
      "Epoch 382/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1285 - val_loss: 25.8471\n",
      "Epoch 383/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2290 - val_loss: 25.6513\n",
      "Epoch 384/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2129 - val_loss: 25.8870\n",
      "Epoch 385/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1199 - val_loss: 25.9396\n",
      "Epoch 386/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1037 - val_loss: 25.8548\n",
      "Epoch 387/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0989 - val_loss: 25.7710\n",
      "Epoch 388/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0778 - val_loss: 25.7612\n",
      "Epoch 389/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0647 - val_loss: 25.7994\n",
      "Epoch 390/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0660 - val_loss: 25.8207\n",
      "Epoch 391/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0576 - val_loss: 25.6984\n",
      "Epoch 392/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1814 - val_loss: 25.7342\n",
      "Epoch 393/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.5636 - val_loss: 25.7415\n",
      "Epoch 394/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.4955 - val_loss: 25.6698\n",
      "Epoch 395/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2908 - val_loss: 25.6516\n",
      "Epoch 396/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1247 - val_loss: 25.7230\n",
      "Epoch 397/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.0571 - val_loss: 25.7688\n",
      "Epoch 398/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.0553 - val_loss: 25.7963\n",
      "Epoch 399/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0602 - val_loss: 25.8001\n",
      "Epoch 400/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0600 - val_loss: 25.8314\n",
      "Epoch 401/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0696 - val_loss: 25.9618\n",
      "Epoch 402/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1405 - val_loss: 25.9508\n",
      "Epoch 403/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1221 - val_loss: 25.9755\n",
      "Epoch 404/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0859 - val_loss: 25.8675\n",
      "Epoch 405/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0763 - val_loss: 25.8098\n",
      "Epoch 406/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0638 - val_loss: 25.7466\n",
      "Epoch 407/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0630 - val_loss: 25.7652\n",
      "Epoch 408/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0598 - val_loss: 25.7413\n",
      "Epoch 409/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0583 - val_loss: 25.7623\n",
      "Epoch 410/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1053 - val_loss: 25.8823\n",
      "Epoch 411/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0872 - val_loss: 25.8103\n",
      "Epoch 412/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0657 - val_loss: 25.7740\n",
      "Epoch 413/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0718 - val_loss: 25.7544\n",
      "Epoch 414/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0213 - val_loss: 25.8469\n",
      "Epoch 415/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0869 - val_loss: 25.8913\n",
      "Epoch 416/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1201 - val_loss: 25.9325\n",
      "Epoch 417/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0947 - val_loss: 25.8206\n",
      "Epoch 418/1000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 33.0713 - val_loss: 25.8105\n",
      "Epoch 419/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.0729 - val_loss: 25.8176\n",
      "Epoch 420/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.1133 - val_loss: 25.9659\n",
      "Epoch 421/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1212 - val_loss: 25.9161\n",
      "Epoch 422/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0885 - val_loss: 25.8663\n",
      "Epoch 423/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0593 - val_loss: 25.8123\n",
      "Epoch 424/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0613 - val_loss: 25.7743\n",
      "Epoch 425/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0494 - val_loss: 25.7634\n",
      "Epoch 426/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0628 - val_loss: 25.7313\n",
      "Epoch 427/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0579 - val_loss: 25.6951\n",
      "Epoch 428/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0673 - val_loss: 25.7071\n",
      "Epoch 429/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0957 - val_loss: 25.6709\n",
      "Epoch 430/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0700 - val_loss: 25.6869\n",
      "Epoch 431/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0904 - val_loss: 25.6796\n",
      "Epoch 432/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0220 - val_loss: 25.7942\n",
      "Epoch 433/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0804 - val_loss: 25.8794\n",
      "Epoch 434/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1391 - val_loss: 25.7228\n",
      "Epoch 435/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0745 - val_loss: 25.7638\n",
      "Epoch 436/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0446 - val_loss: 25.7722\n",
      "Epoch 437/1000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 33.0705 - val_loss: 25.7775\n",
      "Epoch 438/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 33.0534 - val_loss: 25.7376\n",
      "Epoch 439/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.0469 - val_loss: 25.7554\n",
      "Epoch 440/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0432 - val_loss: 25.7675\n",
      "Epoch 441/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0479 - val_loss: 25.7786\n",
      "Epoch 442/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0466 - val_loss: 25.7819\n",
      "Epoch 443/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0545 - val_loss: 25.7454\n",
      "Epoch 444/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.1171 - val_loss: 25.7162\n",
      "Epoch 445/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0358 - val_loss: 25.7966\n",
      "Epoch 446/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0515 - val_loss: 25.8156\n",
      "Epoch 447/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0520 - val_loss: 25.7769\n",
      "Epoch 448/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0161 - val_loss: 25.6996\n",
      "Epoch 449/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1252 - val_loss: 25.6506\n",
      "Epoch 450/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0623 - val_loss: 25.7845\n",
      "Epoch 451/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0352 - val_loss: 25.8363\n",
      "Epoch 452/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0734 - val_loss: 25.9135\n",
      "Epoch 453/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0517 - val_loss: 25.8417\n",
      "Epoch 454/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0471 - val_loss: 25.7852\n",
      "Epoch 455/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0328 - val_loss: 25.7583\n",
      "Epoch 456/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0577 - val_loss: 25.7808\n",
      "Epoch 457/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0895 - val_loss: 25.7105\n",
      "Epoch 458/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0360 - val_loss: 25.7272\n",
      "Epoch 459/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1146 - val_loss: 25.8366\n",
      "Epoch 460/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0783 - val_loss: 25.7629\n",
      "Epoch 461/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0488 - val_loss: 25.7885\n",
      "Epoch 462/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0279 - val_loss: 25.7314\n",
      "Epoch 463/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0672 - val_loss: 25.7271\n",
      "Epoch 464/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0480 - val_loss: 25.7516\n",
      "Epoch 465/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.1807 - val_loss: 25.6419\n",
      "Epoch 466/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1348 - val_loss: 25.6674\n",
      "Epoch 467/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0311 - val_loss: 25.7675\n",
      "Epoch 468/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1464 - val_loss: 25.8872\n",
      "Epoch 469/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9668 - val_loss: 25.6843\n",
      "Epoch 470/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0826 - val_loss: 25.7240\n",
      "Epoch 471/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1546 - val_loss: 26.0875\n",
      "Epoch 472/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1370 - val_loss: 25.9011\n",
      "Epoch 473/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0615 - val_loss: 25.7816\n",
      "Epoch 474/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0400 - val_loss: 25.6725\n",
      "Epoch 475/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0972 - val_loss: 25.6533\n",
      "Epoch 476/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1910 - val_loss: 25.6208\n",
      "Epoch 477/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0974 - val_loss: 25.6371\n",
      "Epoch 478/1000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 33.1395 - val_loss: 25.5972\n",
      "Epoch 479/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 33.0986 - val_loss: 25.6365\n",
      "Epoch 480/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0546 - val_loss: 25.7323\n",
      "Epoch 481/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0272 - val_loss: 25.6992\n",
      "Epoch 482/1000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 33.0452 - val_loss: 25.7171\n",
      "Epoch 483/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0214 - val_loss: 25.7067\n",
      "Epoch 484/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0645 - val_loss: 25.7823\n",
      "Epoch 485/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0480 - val_loss: 25.7302\n",
      "Epoch 486/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0486 - val_loss: 25.7228\n",
      "Epoch 487/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0623 - val_loss: 25.8063\n",
      "Epoch 488/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0264 - val_loss: 25.6945\n",
      "Epoch 489/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0422 - val_loss: 25.7148\n",
      "Epoch 490/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0469 - val_loss: 25.8169\n",
      "Epoch 491/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0201 - val_loss: 25.8027\n",
      "Epoch 492/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0622 - val_loss: 25.7419\n",
      "Epoch 493/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0309 - val_loss: 25.7883\n",
      "Epoch 494/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0348 - val_loss: 25.7429\n",
      "Epoch 495/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0503 - val_loss: 25.6903\n",
      "Epoch 496/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0719 - val_loss: 25.7299\n",
      "Epoch 497/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0720 - val_loss: 26.3302\n",
      "Epoch 498/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3248 - val_loss: 26.2621\n",
      "Epoch 499/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1259 - val_loss: 25.8785\n",
      "Epoch 500/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0117 - val_loss: 25.8112\n",
      "Epoch 501/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0014 - val_loss: 25.7460\n",
      "Epoch 502/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0569 - val_loss: 25.7213\n",
      "Epoch 503/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.0423 - val_loss: 25.7610\n",
      "Epoch 504/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0437 - val_loss: 25.7479\n",
      "Epoch 505/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0169 - val_loss: 25.8107\n",
      "Epoch 506/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0355 - val_loss: 25.8292\n",
      "Epoch 507/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9945 - val_loss: 25.7397\n",
      "Epoch 508/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1645 - val_loss: 25.6464\n",
      "Epoch 509/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0335 - val_loss: 25.6945\n",
      "Epoch 510/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0398 - val_loss: 25.7441\n",
      "Epoch 511/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0320 - val_loss: 25.7174\n",
      "Epoch 512/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0399 - val_loss: 25.6522\n",
      "Epoch 513/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.7326 - val_loss: 25.9499\n",
      "Epoch 514/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.9482 - val_loss: 25.8372\n",
      "Epoch 515/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.6685 - val_loss: 25.6715\n",
      "Epoch 516/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3616 - val_loss: 25.5801\n",
      "Epoch 517/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2193 - val_loss: 25.6235\n",
      "Epoch 518/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0494 - val_loss: 25.6710\n",
      "Epoch 519/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0191 - val_loss: 25.6722\n",
      "Epoch 520/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0212 - val_loss: 25.6651\n",
      "Epoch 521/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0279 - val_loss: 25.6942\n",
      "Epoch 522/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0259 - val_loss: 25.6927\n",
      "Epoch 523/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0099 - val_loss: 25.6990\n",
      "Epoch 524/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0427 - val_loss: 25.7318\n",
      "Epoch 525/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0379 - val_loss: 25.6963\n",
      "Epoch 526/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0146 - val_loss: 25.7183\n",
      "Epoch 527/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0055 - val_loss: 25.7345\n",
      "Epoch 528/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9906 - val_loss: 25.8227\n",
      "Epoch 529/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9997 - val_loss: 25.6479\n",
      "Epoch 530/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0431 - val_loss: 25.6221\n",
      "Epoch 531/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0530 - val_loss: 25.6385\n",
      "Epoch 532/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0808 - val_loss: 25.8686\n",
      "Epoch 533/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0320 - val_loss: 25.8045\n",
      "Epoch 534/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0678 - val_loss: 25.7391\n",
      "Epoch 535/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0066 - val_loss: 25.7279\n",
      "Epoch 536/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0250 - val_loss: 25.7206\n",
      "Epoch 537/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9928 - val_loss: 25.7439\n",
      "Epoch 538/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0048 - val_loss: 25.7761\n",
      "Epoch 539/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0177 - val_loss: 25.7468\n",
      "Epoch 540/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0056 - val_loss: 25.8222\n",
      "Epoch 541/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0780 - val_loss: 26.1088\n",
      "Epoch 542/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1905 - val_loss: 26.1640\n",
      "Epoch 543/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1627 - val_loss: 25.9848\n",
      "Epoch 544/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0607 - val_loss: 25.8784\n",
      "Epoch 545/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0165 - val_loss: 25.7523\n",
      "Epoch 546/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9989 - val_loss: 25.7338\n",
      "Epoch 547/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0375 - val_loss: 25.8899\n",
      "Epoch 548/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0393 - val_loss: 25.8155\n",
      "Epoch 549/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0153 - val_loss: 25.7840\n",
      "Epoch 550/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9917 - val_loss: 25.7709\n",
      "Epoch 551/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0186 - val_loss: 25.7257\n",
      "Epoch 552/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0154 - val_loss: 25.7637\n",
      "Epoch 553/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9933 - val_loss: 25.7628\n",
      "Epoch 554/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9951 - val_loss: 25.7723\n",
      "Epoch 555/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0316 - val_loss: 25.8031\n",
      "Epoch 556/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0180 - val_loss: 25.8141\n",
      "Epoch 557/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9856 - val_loss: 25.7727\n",
      "Epoch 558/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9955 - val_loss: 25.7526\n",
      "Epoch 559/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9984 - val_loss: 25.7767\n",
      "Epoch 560/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0105 - val_loss: 25.7713\n",
      "Epoch 561/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0228 - val_loss: 25.7515\n",
      "Epoch 562/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9811 - val_loss: 25.7536\n",
      "Epoch 563/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0778 - val_loss: 25.6121\n",
      "Epoch 564/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0644 - val_loss: 25.6197\n",
      "Epoch 565/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0187 - val_loss: 25.6453\n",
      "Epoch 566/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0287 - val_loss: 25.7357\n",
      "Epoch 567/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0300 - val_loss: 25.7407\n",
      "Epoch 568/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9949 - val_loss: 25.9935\n",
      "Epoch 569/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2663 - val_loss: 26.4488\n",
      "Epoch 570/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.3438 - val_loss: 26.1874\n",
      "Epoch 571/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0765 - val_loss: 25.9573\n",
      "Epoch 572/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9853 - val_loss: 25.8407\n",
      "Epoch 573/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9716 - val_loss: 25.7717\n",
      "Epoch 574/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1480 - val_loss: 25.6848\n",
      "Epoch 575/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0005 - val_loss: 25.7180\n",
      "Epoch 576/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0509 - val_loss: 25.8890\n",
      "Epoch 577/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0403 - val_loss: 25.8531\n",
      "Epoch 578/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0002 - val_loss: 25.8343\n",
      "Epoch 579/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9971 - val_loss: 25.7812\n",
      "Epoch 580/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0374 - val_loss: 25.7060\n",
      "Epoch 581/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0451 - val_loss: 25.6773\n",
      "Epoch 582/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9745 - val_loss: 25.6948\n",
      "Epoch 583/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0195 - val_loss: 25.5527\n",
      "Epoch 584/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1471 - val_loss: 25.5400\n",
      "Epoch 585/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1500 - val_loss: 25.6247\n",
      "Epoch 586/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9907 - val_loss: 25.6441\n",
      "Epoch 587/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0144 - val_loss: 25.7879\n",
      "Epoch 588/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9958 - val_loss: 25.7455\n",
      "Epoch 589/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0157 - val_loss: 25.6830\n",
      "Epoch 590/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9946 - val_loss: 25.7221\n",
      "Epoch 591/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0083 - val_loss: 25.7491\n",
      "Epoch 592/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9957 - val_loss: 25.6761\n",
      "Epoch 593/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0624 - val_loss: 25.7389\n",
      "Epoch 594/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9994 - val_loss: 25.6641\n",
      "Epoch 595/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9848 - val_loss: 25.6589\n",
      "Epoch 596/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9814 - val_loss: 25.6949\n",
      "Epoch 597/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9802 - val_loss: 25.7064\n",
      "Epoch 598/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9829 - val_loss: 25.7268\n",
      "Epoch 599/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9875 - val_loss: 25.7298\n",
      "Epoch 600/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0567 - val_loss: 25.9439\n",
      "Epoch 601/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0277 - val_loss: 25.7701\n",
      "Epoch 602/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9772 - val_loss: 25.7663\n",
      "Epoch 603/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9955 - val_loss: 25.7369\n",
      "Epoch 604/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0133 - val_loss: 25.6837\n",
      "Epoch 605/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0321 - val_loss: 25.9268\n",
      "Epoch 606/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0607 - val_loss: 25.9524\n",
      "Epoch 607/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0353 - val_loss: 25.8421\n",
      "Epoch 608/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9683 - val_loss: 25.6571\n",
      "Epoch 609/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9825 - val_loss: 25.6550\n",
      "Epoch 610/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9696 - val_loss: 25.6370\n",
      "Epoch 611/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9753 - val_loss: 25.6214\n",
      "Epoch 612/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9750 - val_loss: 25.6510\n",
      "Epoch 613/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0036 - val_loss: 25.7523\n",
      "Epoch 614/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9728 - val_loss: 25.7465\n",
      "Epoch 615/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9786 - val_loss: 25.7624\n",
      "Epoch 616/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0016 - val_loss: 25.6801\n",
      "Epoch 617/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0014 - val_loss: 25.7335\n",
      "Epoch 618/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9777 - val_loss: 25.6268\n",
      "Epoch 619/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9995 - val_loss: 25.6918\n",
      "Epoch 620/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9982 - val_loss: 25.6926\n",
      "Epoch 621/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0455 - val_loss: 25.6130\n",
      "Epoch 622/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9862 - val_loss: 25.6593\n",
      "Epoch 623/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9983 - val_loss: 25.6631\n",
      "Epoch 624/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9951 - val_loss: 25.7769\n",
      "Epoch 625/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9521 - val_loss: 26.1810\n",
      "Epoch 626/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.3492 - val_loss: 26.2366\n",
      "Epoch 627/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0961 - val_loss: 25.8400\n",
      "Epoch 628/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9637 - val_loss: 25.6205\n",
      "Epoch 629/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9861 - val_loss: 25.5663\n",
      "Epoch 630/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9969 - val_loss: 25.6131\n",
      "Epoch 631/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9725 - val_loss: 25.6652\n",
      "Epoch 632/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9743 - val_loss: 25.6503\n",
      "Epoch 633/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1445 - val_loss: 25.7077\n",
      "Epoch 634/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8529 - val_loss: 25.5375\n",
      "Epoch 635/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1210 - val_loss: 25.5744\n",
      "Epoch 636/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0338 - val_loss: 25.6306\n",
      "Epoch 637/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9981 - val_loss: 25.6695\n",
      "Epoch 638/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0300 - val_loss: 25.6194\n",
      "Epoch 639/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9443 - val_loss: 25.7461\n",
      "Epoch 640/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.3541 - val_loss: 26.2612\n",
      "Epoch 641/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.1720 - val_loss: 25.8522\n",
      "Epoch 642/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1022 - val_loss: 25.5697\n",
      "Epoch 643/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2264 - val_loss: 25.7020\n",
      "Epoch 644/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9978 - val_loss: 25.7095\n",
      "Epoch 645/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9540 - val_loss: 25.7391\n",
      "Epoch 646/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0448 - val_loss: 25.9164\n",
      "Epoch 647/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.5130 - val_loss: 26.3948\n",
      "Epoch 648/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.0614 - val_loss: 25.6812\n",
      "Epoch 649/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9561 - val_loss: 25.5913\n",
      "Epoch 650/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9942 - val_loss: 25.5870\n",
      "Epoch 651/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0371 - val_loss: 25.6684\n",
      "Epoch 652/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9775 - val_loss: 25.6782\n",
      "Epoch 653/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9312 - val_loss: 25.8672\n",
      "Epoch 654/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.0672 - val_loss: 26.2322\n",
      "Epoch 655/1000\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 33.2476 - val_loss: 26.1139\n",
      "Epoch 656/1000\n",
      "12/12 [==============================] - 0s 11ms/step - loss: 33.1946 - val_loss: 25.6283\n",
      "Epoch 657/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9813 - val_loss: 25.6417\n",
      "Epoch 658/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9631 - val_loss: 25.6516\n",
      "Epoch 659/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9610 - val_loss: 25.7784\n",
      "Epoch 660/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.0825 - val_loss: 26.2600\n",
      "Epoch 661/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1999 - val_loss: 26.0025\n",
      "Epoch 662/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.1919 - val_loss: 25.6557\n",
      "Epoch 663/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.3307 - val_loss: 26.2377\n",
      "Epoch 664/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 33.1491 - val_loss: 26.0160\n",
      "Epoch 665/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9743 - val_loss: 25.8426\n",
      "Epoch 666/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9418 - val_loss: 25.7934\n",
      "Epoch 667/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9430 - val_loss: 25.7546\n",
      "Epoch 668/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9639 - val_loss: 25.9521\n",
      "Epoch 669/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9941 - val_loss: 25.8845\n",
      "Epoch 670/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9621 - val_loss: 25.7932\n",
      "Epoch 671/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9460 - val_loss: 25.7567\n",
      "Epoch 672/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9827 - val_loss: 25.5998\n",
      "Epoch 673/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0427 - val_loss: 25.6412\n",
      "Epoch 674/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9724 - val_loss: 25.6383\n",
      "Epoch 675/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9595 - val_loss: 25.7127\n",
      "Epoch 676/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9439 - val_loss: 25.7347\n",
      "Epoch 677/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9711 - val_loss: 25.7438\n",
      "Epoch 678/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9181 - val_loss: 25.5835\n",
      "Epoch 679/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0624 - val_loss: 25.5860\n",
      "Epoch 680/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9830 - val_loss: 25.6862\n",
      "Epoch 681/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9768 - val_loss: 25.6923\n",
      "Epoch 682/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9326 - val_loss: 25.8493\n",
      "Epoch 683/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.1175 - val_loss: 26.0786\n",
      "Epoch 684/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0822 - val_loss: 25.7836\n",
      "Epoch 685/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9859 - val_loss: 25.6926\n",
      "Epoch 686/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9352 - val_loss: 25.7163\n",
      "Epoch 687/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9527 - val_loss: 25.7117\n",
      "Epoch 688/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9532 - val_loss: 25.7046\n",
      "Epoch 689/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9545 - val_loss: 25.6969\n",
      "Epoch 690/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9269 - val_loss: 25.7542\n",
      "Epoch 691/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9532 - val_loss: 25.7728\n",
      "Epoch 692/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 32.9793 - val_loss: 25.6685\n",
      "Epoch 693/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9924 - val_loss: 25.6878\n",
      "Epoch 694/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.0678 - val_loss: 25.6582\n",
      "Epoch 695/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 33.2708 - val_loss: 26.0314\n",
      "Epoch 696/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9764 - val_loss: 25.7481\n",
      "Epoch 697/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 32.9518 - val_loss: 25.6604\n",
      "Epoch 698/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 32.9786 - val_loss: 26.1936\n",
      "Epoch 699/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.1626 - val_loss: 26.0801\n",
      "Epoch 700/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0304 - val_loss: 25.7616\n",
      "Epoch 701/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 32.8884 - val_loss: 25.5974\n",
      "Epoch 702/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9682 - val_loss: 25.6083\n",
      "Epoch 703/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9682 - val_loss: 25.6771\n",
      "Epoch 704/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9393 - val_loss: 25.6952\n",
      "Epoch 705/1000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 32.9174 - val_loss: 25.7738\n",
      "Epoch 706/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.1345 - val_loss: 26.1895\n",
      "Epoch 707/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9247 - val_loss: 25.8708\n",
      "Epoch 708/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9126 - val_loss: 25.6951\n",
      "Epoch 709/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.7729 - val_loss: 26.0548\n",
      "Epoch 710/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 33.0367 - val_loss: 26.6291\n",
      "Epoch 711/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.6155 - val_loss: 26.8279\n",
      "Epoch 712/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.5656 - val_loss: 26.1674\n",
      "Epoch 713/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9909 - val_loss: 25.9829\n",
      "Epoch 714/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9586 - val_loss: 25.8578\n",
      "Epoch 715/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9293 - val_loss: 25.7049\n",
      "Epoch 716/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0256 - val_loss: 25.7059\n",
      "Epoch 717/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.7890 - val_loss: 26.2018\n",
      "Epoch 718/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0785 - val_loss: 26.1584\n",
      "Epoch 719/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0045 - val_loss: 26.0556\n",
      "Epoch 720/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0379 - val_loss: 26.2514\n",
      "Epoch 721/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0728 - val_loss: 25.9875\n",
      "Epoch 722/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9146 - val_loss: 25.8083\n",
      "Epoch 723/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1472 - val_loss: 25.6706\n",
      "Epoch 724/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.1583 - val_loss: 25.6830\n",
      "Epoch 725/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0156 - val_loss: 25.7438\n",
      "Epoch 726/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9391 - val_loss: 25.8228\n",
      "Epoch 727/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9456 - val_loss: 25.9225\n",
      "Epoch 728/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9350 - val_loss: 25.8926\n",
      "Epoch 729/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9191 - val_loss: 25.8581\n",
      "Epoch 730/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9306 - val_loss: 25.8437\n",
      "Epoch 731/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9526 - val_loss: 25.8798\n",
      "Epoch 732/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9215 - val_loss: 25.8185\n",
      "Epoch 733/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9274 - val_loss: 25.7745\n",
      "Epoch 734/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9182 - val_loss: 25.7720\n",
      "Epoch 735/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9293 - val_loss: 25.7958\n",
      "Epoch 736/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9149 - val_loss: 25.7984\n",
      "Epoch 737/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9266 - val_loss: 25.7911\n",
      "Epoch 738/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0476 - val_loss: 25.9250\n",
      "Epoch 739/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8771 - val_loss: 25.7647\n",
      "Epoch 740/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0008 - val_loss: 25.6770\n",
      "Epoch 741/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9527 - val_loss: 25.7166\n",
      "Epoch 742/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0580 - val_loss: 25.8689\n",
      "Epoch 743/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8961 - val_loss: 25.7911\n",
      "Epoch 744/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9904 - val_loss: 25.7166\n",
      "Epoch 745/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9932 - val_loss: 25.8323\n",
      "Epoch 746/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9231 - val_loss: 25.7835\n",
      "Epoch 747/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9326 - val_loss: 26.0143\n",
      "Epoch 748/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0049 - val_loss: 26.0023\n",
      "Epoch 749/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9217 - val_loss: 25.8318\n",
      "Epoch 750/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8912 - val_loss: 25.7049\n",
      "Epoch 751/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9740 - val_loss: 25.6208\n",
      "Epoch 752/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9947 - val_loss: 25.6729\n",
      "Epoch 753/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9442 - val_loss: 25.7301\n",
      "Epoch 754/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9899 - val_loss: 25.8432\n",
      "Epoch 755/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9239 - val_loss: 25.7932\n",
      "Epoch 756/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8896 - val_loss: 25.7953\n",
      "Epoch 757/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8965 - val_loss: 25.7541\n",
      "Epoch 758/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8983 - val_loss: 25.7261\n",
      "Epoch 759/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9264 - val_loss: 25.7331\n",
      "Epoch 760/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9042 - val_loss: 25.7524\n",
      "Epoch 761/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9162 - val_loss: 25.7759\n",
      "Epoch 762/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9459 - val_loss: 25.7019\n",
      "Epoch 763/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0116 - val_loss: 25.8777\n",
      "Epoch 764/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9294 - val_loss: 25.8021\n",
      "Epoch 765/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0220 - val_loss: 26.2242\n",
      "Epoch 766/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0669 - val_loss: 25.8287\n",
      "Epoch 767/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0114 - val_loss: 25.6671\n",
      "Epoch 768/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9092 - val_loss: 26.2170\n",
      "Epoch 769/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.1211 - val_loss: 26.1363\n",
      "Epoch 770/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9567 - val_loss: 25.9309\n",
      "Epoch 771/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0378 - val_loss: 26.1851\n",
      "Epoch 772/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9550 - val_loss: 25.8712\n",
      "Epoch 773/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9584 - val_loss: 25.7212\n",
      "Epoch 774/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9639 - val_loss: 25.8881\n",
      "Epoch 775/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0551 - val_loss: 26.2652\n",
      "Epoch 776/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0227 - val_loss: 26.0177\n",
      "Epoch 777/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0099 - val_loss: 25.7550\n",
      "Epoch 778/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9149 - val_loss: 25.7760\n",
      "Epoch 779/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8965 - val_loss: 25.8288\n",
      "Epoch 780/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9588 - val_loss: 26.0681\n",
      "Epoch 781/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0181 - val_loss: 25.9084\n",
      "Epoch 782/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9047 - val_loss: 25.8631\n",
      "Epoch 783/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8977 - val_loss: 25.7870\n",
      "Epoch 784/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9109 - val_loss: 25.7711\n",
      "Epoch 785/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9283 - val_loss: 25.7319\n",
      "Epoch 786/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9000 - val_loss: 25.8226\n",
      "Epoch 787/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9013 - val_loss: 25.7457\n",
      "Epoch 788/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9124 - val_loss: 25.7516\n",
      "Epoch 789/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.0496 - val_loss: 25.7256\n",
      "Epoch 790/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8133 - val_loss: 26.2496\n",
      "Epoch 791/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0824 - val_loss: 26.0639\n",
      "Epoch 792/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0036 - val_loss: 25.7748\n",
      "Epoch 793/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8861 - val_loss: 25.7420\n",
      "Epoch 794/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9195 - val_loss: 25.6587\n",
      "Epoch 795/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8952 - val_loss: 25.7021\n",
      "Epoch 796/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9285 - val_loss: 25.8033\n",
      "Epoch 797/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9817 - val_loss: 25.7448\n",
      "Epoch 798/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9392 - val_loss: 25.7510\n",
      "Epoch 799/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8764 - val_loss: 25.7637\n",
      "Epoch 800/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9208 - val_loss: 25.8371\n",
      "Epoch 801/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9346 - val_loss: 25.7777\n",
      "Epoch 802/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9602 - val_loss: 25.6617\n",
      "Epoch 803/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9081 - val_loss: 25.7415\n",
      "Epoch 804/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9130 - val_loss: 25.6920\n",
      "Epoch 805/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.2826 - val_loss: 25.5891\n",
      "Epoch 806/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.2007 - val_loss: 25.5367\n",
      "Epoch 807/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8941 - val_loss: 25.8320\n",
      "Epoch 808/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0698 - val_loss: 26.0564\n",
      "Epoch 809/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0157 - val_loss: 25.7710\n",
      "Epoch 810/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8772 - val_loss: 25.7597\n",
      "Epoch 811/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8872 - val_loss: 25.7056\n",
      "Epoch 812/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8753 - val_loss: 25.7241\n",
      "Epoch 813/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8686 - val_loss: 25.7494\n",
      "Epoch 814/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8656 - val_loss: 25.7095\n",
      "Epoch 815/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8725 - val_loss: 25.7168\n",
      "Epoch 816/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8879 - val_loss: 25.6977\n",
      "Epoch 817/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8686 - val_loss: 25.7394\n",
      "Epoch 818/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8649 - val_loss: 25.7622\n",
      "Epoch 819/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9040 - val_loss: 25.8090\n",
      "Epoch 820/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9570 - val_loss: 25.8549\n",
      "Epoch 821/1000\n",
      "12/12 [==============================] - 0s 14ms/step - loss: 32.8840 - val_loss: 25.6833\n",
      "Epoch 822/1000\n",
      "12/12 [==============================] - 0s 16ms/step - loss: 32.8681 - val_loss: 25.6593\n",
      "Epoch 823/1000\n",
      "12/12 [==============================] - 0s 12ms/step - loss: 32.9021 - val_loss: 25.6660\n",
      "Epoch 824/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9148 - val_loss: 25.6928\n",
      "Epoch 825/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9225 - val_loss: 25.7705\n",
      "Epoch 826/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9307 - val_loss: 25.6890\n",
      "Epoch 827/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8793 - val_loss: 25.7825\n",
      "Epoch 828/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0330 - val_loss: 26.1150\n",
      "Epoch 829/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8941 - val_loss: 25.6525\n",
      "Epoch 830/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9357 - val_loss: 25.6216\n",
      "Epoch 831/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9915 - val_loss: 25.6189\n",
      "Epoch 832/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8669 - val_loss: 25.7068\n",
      "Epoch 833/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.8661 - val_loss: 25.7424\n",
      "Epoch 834/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.8613 - val_loss: 25.7309\n",
      "Epoch 835/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.8578 - val_loss: 25.7332\n",
      "Epoch 836/1000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 32.8706 - val_loss: 25.7382\n",
      "Epoch 837/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.8915 - val_loss: 25.7021\n",
      "Epoch 838/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9960 - val_loss: 25.9372\n",
      "Epoch 839/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.1226 - val_loss: 26.2845\n",
      "Epoch 840/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 33.2975 - val_loss: 25.7373\n",
      "Epoch 841/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9618 - val_loss: 25.9581\n",
      "Epoch 842/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8988 - val_loss: 25.8288\n",
      "Epoch 843/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.8632 - val_loss: 25.7922\n",
      "Epoch 844/1000\n",
      "12/12 [==============================] - 0s 8ms/step - loss: 32.8872 - val_loss: 25.7447\n",
      "Epoch 845/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.8718 - val_loss: 25.7285\n",
      "Epoch 846/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.8828 - val_loss: 25.6537\n",
      "Epoch 847/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.8882 - val_loss: 25.7046\n",
      "Epoch 848/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8016 - val_loss: 26.0130\n",
      "Epoch 849/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.4377 - val_loss: 26.4162\n",
      "Epoch 850/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8912 - val_loss: 25.6027\n",
      "Epoch 851/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9633 - val_loss: 25.5839\n",
      "Epoch 852/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9470 - val_loss: 25.6774\n",
      "Epoch 853/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9187 - val_loss: 25.6828\n",
      "Epoch 854/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9120 - val_loss: 25.7214\n",
      "Epoch 855/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8474 - val_loss: 25.6861\n",
      "Epoch 856/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9191 - val_loss: 25.6590\n",
      "Epoch 857/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8767 - val_loss: 25.7212\n",
      "Epoch 858/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8701 - val_loss: 25.6281\n",
      "Epoch 859/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9756 - val_loss: 25.6327\n",
      "Epoch 860/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.2514 - val_loss: 26.2366\n",
      "Epoch 861/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0105 - val_loss: 26.0112\n",
      "Epoch 862/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0292 - val_loss: 25.7310\n",
      "Epoch 863/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8594 - val_loss: 25.7541\n",
      "Epoch 864/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8709 - val_loss: 25.7872\n",
      "Epoch 865/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8753 - val_loss: 25.6873\n",
      "Epoch 866/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9033 - val_loss: 25.8274\n",
      "Epoch 867/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8752 - val_loss: 25.8306\n",
      "Epoch 868/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.7795 - val_loss: 26.3588\n",
      "Epoch 869/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0783 - val_loss: 26.1886\n",
      "Epoch 870/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9138 - val_loss: 25.8110\n",
      "Epoch 871/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8350 - val_loss: 25.7698\n",
      "Epoch 872/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8521 - val_loss: 25.7278\n",
      "Epoch 873/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8823 - val_loss: 25.8041\n",
      "Epoch 874/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8696 - val_loss: 25.7326\n",
      "Epoch 875/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8615 - val_loss: 25.7774\n",
      "Epoch 876/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8458 - val_loss: 25.7796\n",
      "Epoch 877/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8722 - val_loss: 25.7182\n",
      "Epoch 878/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9146 - val_loss: 25.8131\n",
      "Epoch 879/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8771 - val_loss: 25.7537\n",
      "Epoch 880/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8787 - val_loss: 25.7893\n",
      "Epoch 881/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8967 - val_loss: 26.1588\n",
      "Epoch 882/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9660 - val_loss: 26.0295\n",
      "Epoch 883/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9240 - val_loss: 25.7696\n",
      "Epoch 884/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8850 - val_loss: 25.6220\n",
      "Epoch 885/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9168 - val_loss: 25.6683\n",
      "Epoch 886/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8610 - val_loss: 25.7261\n",
      "Epoch 887/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9299 - val_loss: 25.6601\n",
      "Epoch 888/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8715 - val_loss: 25.7111\n",
      "Epoch 889/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8391 - val_loss: 25.6994\n",
      "Epoch 890/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9402 - val_loss: 25.5826\n",
      "Epoch 891/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9093 - val_loss: 25.7071\n",
      "Epoch 892/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8368 - val_loss: 25.8135\n",
      "Epoch 893/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8033 - val_loss: 26.1529\n",
      "Epoch 894/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0323 - val_loss: 25.7932\n",
      "Epoch 895/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8602 - val_loss: 25.7636\n",
      "Epoch 896/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8373 - val_loss: 25.7162\n",
      "Epoch 897/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8521 - val_loss: 25.7297\n",
      "Epoch 898/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8318 - val_loss: 25.7177\n",
      "Epoch 899/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8518 - val_loss: 25.7021\n",
      "Epoch 900/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8544 - val_loss: 25.8044\n",
      "Epoch 901/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8363 - val_loss: 25.7966\n",
      "Epoch 902/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8428 - val_loss: 25.7411\n",
      "Epoch 903/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8891 - val_loss: 25.7510\n",
      "Epoch 904/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.6834 - val_loss: 26.2688\n",
      "Epoch 905/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.1849 - val_loss: 26.2359\n",
      "Epoch 906/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9674 - val_loss: 25.8417\n",
      "Epoch 907/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8733 - val_loss: 25.7573\n",
      "Epoch 908/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8667 - val_loss: 25.8525\n",
      "Epoch 909/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9365 - val_loss: 25.7790\n",
      "Epoch 910/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 33.2733 - val_loss: 26.4267\n",
      "Epoch 911/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8105 - val_loss: 25.6864\n",
      "Epoch 912/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8814 - val_loss: 25.5948\n",
      "Epoch 913/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9569 - val_loss: 25.5796\n",
      "Epoch 914/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9827 - val_loss: 25.5887\n",
      "Epoch 915/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.9352 - val_loss: 25.6719\n",
      "Epoch 916/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8685 - val_loss: 25.6455\n",
      "Epoch 917/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8765 - val_loss: 25.6450\n",
      "Epoch 918/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8936 - val_loss: 25.6510\n",
      "Epoch 919/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8390 - val_loss: 25.6892\n",
      "Epoch 920/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8678 - val_loss: 25.7785\n",
      "Epoch 921/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8338 - val_loss: 25.8429\n",
      "Epoch 922/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8313 - val_loss: 25.7480\n",
      "Epoch 923/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8300 - val_loss: 25.6498\n",
      "Epoch 924/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9638 - val_loss: 25.5660\n",
      "Epoch 925/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.7867 - val_loss: 25.7643\n",
      "Epoch 926/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8063 - val_loss: 25.8428\n",
      "Epoch 927/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8278 - val_loss: 25.8260\n",
      "Epoch 928/1000\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 32.8554 - val_loss: 25.7112\n",
      "Epoch 929/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8316 - val_loss: 25.5731\n",
      "Epoch 930/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.7372 - val_loss: 25.9110\n",
      "Epoch 931/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8780 - val_loss: 25.9453\n",
      "Epoch 932/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.1890 - val_loss: 26.1837\n",
      "Epoch 933/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.7689 - val_loss: 25.6582\n",
      "Epoch 934/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9193 - val_loss: 25.5438\n",
      "Epoch 935/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.9165 - val_loss: 25.6001\n",
      "Epoch 936/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9552 - val_loss: 25.8568\n",
      "Epoch 937/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8468 - val_loss: 25.7301\n",
      "Epoch 938/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8247 - val_loss: 25.7554\n",
      "Epoch 939/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.7343 - val_loss: 25.5845\n",
      "Epoch 940/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8956 - val_loss: 25.6252\n",
      "Epoch 941/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8308 - val_loss: 26.1983\n",
      "Epoch 942/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 33.0534 - val_loss: 26.2095\n",
      "Epoch 943/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9760 - val_loss: 26.0996\n",
      "Epoch 944/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9133 - val_loss: 25.7627\n",
      "Epoch 945/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8418 - val_loss: 25.7579\n",
      "Epoch 946/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8757 - val_loss: 25.5987\n",
      "Epoch 947/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8649 - val_loss: 25.5974\n",
      "Epoch 948/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8686 - val_loss: 25.7133\n",
      "Epoch 949/1000\n",
      "12/12 [==============================] - 0s 6ms/step - loss: 32.7964 - val_loss: 25.7417\n",
      "Epoch 950/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.8072 - val_loss: 25.7586\n",
      "Epoch 951/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8562 - val_loss: 25.6342\n",
      "Epoch 952/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8214 - val_loss: 25.6645\n",
      "Epoch 953/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.8771 - val_loss: 25.6420\n",
      "Epoch 954/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.8370 - val_loss: 25.6371\n",
      "Epoch 955/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8216 - val_loss: 25.7500\n",
      "Epoch 956/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8182 - val_loss: 25.7704\n",
      "Epoch 957/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8423 - val_loss: 25.8432\n",
      "Epoch 958/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8526 - val_loss: 25.8202\n",
      "Epoch 959/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8517 - val_loss: 26.0596\n",
      "Epoch 960/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9881 - val_loss: 26.1605\n",
      "Epoch 961/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9006 - val_loss: 25.7936\n",
      "Epoch 962/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8828 - val_loss: 25.5153\n",
      "Epoch 963/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8861 - val_loss: 25.5643\n",
      "Epoch 964/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9334 - val_loss: 25.5499\n",
      "Epoch 965/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.7943 - val_loss: 25.7048\n",
      "Epoch 966/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8100 - val_loss: 26.2252\n",
      "Epoch 967/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9679 - val_loss: 25.8189\n",
      "Epoch 968/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8871 - val_loss: 25.5904\n",
      "Epoch 969/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8693 - val_loss: 25.7570\n",
      "Epoch 970/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8767 - val_loss: 25.8115\n",
      "Epoch 971/1000\n",
      "12/12 [==============================] - 0s 9ms/step - loss: 32.8530 - val_loss: 25.7723\n",
      "Epoch 972/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.9883 - val_loss: 26.3190\n",
      "Epoch 973/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.1552 - val_loss: 26.2277\n",
      "Epoch 974/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9302 - val_loss: 25.7920\n",
      "Epoch 975/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8471 - val_loss: 25.5028\n",
      "Epoch 976/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9350 - val_loss: 25.5758\n",
      "Epoch 977/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8354 - val_loss: 25.5887\n",
      "Epoch 978/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8277 - val_loss: 25.6065\n",
      "Epoch 979/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8829 - val_loss: 25.5455\n",
      "Epoch 980/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8602 - val_loss: 25.6945\n",
      "Epoch 981/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.7742 - val_loss: 26.0368\n",
      "Epoch 982/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8888 - val_loss: 25.7579\n",
      "Epoch 983/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8039 - val_loss: 25.6598\n",
      "Epoch 984/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8220 - val_loss: 25.8211\n",
      "Epoch 985/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8610 - val_loss: 25.7432\n",
      "Epoch 986/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8073 - val_loss: 25.6275\n",
      "Epoch 987/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 32.8704 - val_loss: 25.4837\n",
      "Epoch 988/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.9541 - val_loss: 25.5295\n",
      "Epoch 989/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8292 - val_loss: 25.6526\n",
      "Epoch 990/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.8013 - val_loss: 25.7539\n",
      "Epoch 991/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.8088 - val_loss: 25.8428\n",
      "Epoch 992/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.7864 - val_loss: 25.6654\n",
      "Epoch 993/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.7951 - val_loss: 25.5857\n",
      "Epoch 994/1000\n",
      "12/12 [==============================] - 0s 7ms/step - loss: 32.9237 - val_loss: 25.4706\n",
      "Epoch 995/1000\n",
      "12/12 [==============================] - 0s 5ms/step - loss: 33.0934 - val_loss: 25.4574\n",
      "Epoch 996/1000\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 32.9556 - val_loss: 25.5093\n",
      "Epoch 997/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.8172 - val_loss: 25.6598\n",
      "Epoch 998/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0651 - val_loss: 26.2472\n",
      "Epoch 999/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 33.0447 - val_loss: 26.0581\n",
      "Epoch 1000/1000\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 32.7619 - val_loss: 25.6704\n"
     ]
    }
   ],
   "source": [
    "stop_training = EarlyStoppingByLossVal()\n",
    "\n",
    "model_fit = model.fit(X_train, y_train,\n",
    "                      validation_data=(X_val, y_val),\n",
    "                      epochs=1000,\n",
    "                      callbacks=[stop_training])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'val_loss'])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_fit.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f79db318b20>]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(model_fit.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
  },
  "kernelspec": {
   "display_name": "Python 3.10.0 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
